容器化部署服务的高可用问题
=================


[TOC]

> 容器云平台是现今大规模应用服务管理运维的主要技术，而k8s是最流行的容器编排引擎。
>

## k8s集群节点数的规划

> 主要思路：合理规划集群节点，抵御节点故障问题。

首先通常使用k8s时，通常是管理多台主机组成一个集群。k8s集群可以看做是将所有主机节点组成了一个超大节点，统一的进行调度与管理。组件集群时，如果资源有限，如何划分集群更好是一个值得讨论的事情。

比如总量64C+128GB的资源，可以分为：(64C+128GB)×1=(32C+128GB)×2=(16C+32GB)×4==(8C+16GB)×8等情况，哪种划分更好，可以有两个方向：

### 方向一，大节点，节点数少

比如使用1个大节点，或2个节点；

  * 优点：管理简单，需要维护的主机少；大节点可以运行高资源需求的程序；k8s对节点管理开销少；
  * 缺点：大节点可能运行过多pod，给kubelet增加负担，通常认为临界值是1个节点100个pod；pod有效复制程度低，不能通过增加pod副本数提升可用性；同时爆炸半径大，比如2个节点1个故障则导致50%资源损失；
### 方向二，小节点，节点数多
比如使用4个节点或者更多；

  * 优点：pod有效复制程度高，增加pod副本可以分布在不同节点，节点故障带来的影响小，比如4个节点1个故障影响的资源是25%；

  * 缺点：节点数过多则管理复杂度高，每个节点的系统服务也会耗费资源；

集群节点规划时，如果要获得较高可用性，其实通常应避免过少或过多的节点数，追求一个平衡值。

当1个主机故障时，单节点的k8s直接不可用，2节点集群影响50%，由于集群通常不会一直预留50%空闲资源，可能有些服务因剩余资源过少而无法漂移，系统整体的负载能力也下降很多，4节点集群影响25%，如果合理设置pod资源与副本数预留一定的空闲资源，则集群剩余75%的资源可以继续正常承载系统业务。

![](https://bed.cdpt.pro/ibed/2021/12/16/DgeZa51gP.png)

所以，如果资源允许的情况下，可以规划4个节点或以上的集群，并保证有一定的空闲资源以抵御个别主机宕机的情况。

## pod容器资源规划

> 主要思路：分清主次，提升整体伸缩性，合理利用资源，并留有空余。

k8s容器带来了资源控制能力，能够避免个别服务占用资源过多，但也要用好资源需要合理规划，如果资源设置不合理，要么预留资源过多造成浪费，要么限制得过少导致服务运行缓慢。

必须要说的是，Pod资源规划关系到k8s的资源QoS策略，即三种Qos策略：`Guaranteed`、`BestEffort`、`Burstable`，对应策略为：完全预留资源、完全不预留，和部分预留，具体设置Pod资源时需结合QoS策略和实际环境来考虑。

软件系统通常会包含多个需要运行的服务，当为系统申请资源时，需要为整体系统考虑资源，可能有如下情况要考虑：

### 整体强伸缩性，适应不同规模。
产品部署地点多，就需要考虑很多规模情况，比如较小资源8C+32G规模，大规模可能有64C+256G、128C+512G甚至更多，最小最大部署资源可能差10倍

   可以为系统预设3种规模：

   * 小规模：通常定位成试用、最小化使用；

   * 中等规模：通常定位成一个中等地市规模使用；

   * 大规模：通常定位成一个省级集中规模使用；

     在chart编排时，可以根据变量来自动应用3种情况，比如设置一个规模变量`config.deploy.scale=Small/Medium/Large`，在yaml中根据变量值来设置resources：

     ```yaml
       # 通过部署规模选项，自动决定副本数
       {{- if ( eq .Values.config.deploy.scale "Medium") }}
       replicas: {{.Values.endpoint.medium.replicas}}
       {{- else if ( eq .Values.config.deploy.scale "Large") }}
       replicas: {{.Values.endpoint.large.replicas}}
       {{- else }}
       replicas: {{.Values.endpoint.replicas}}
       {{- end}}
       
       # 通过部署规模选项，自动决定cpu内存资源
       resources:
       {{- if ( eq .Values.config.deploy.scale "Medium") }}
         {{- toYaml .Values.endpoint.medium.resources | nindent 10 }}
       {{- else if ( eq .Values.config.deploy.scale "Large") }}
         {{- toYaml .Values.endpoint.large.resources | nindent 10 }}
       {{- else }}
         {{- toYaml .Values.endpoint.resources | nindent 10 }}
       {{- end }}
     ```


### 有高有低，有保有舍
不应该所有Pod都是`Guaranteed`策略，资源上下限相等虽然可以避免节点空闲资源不足问题，但一方面是容易造成资源空置浪费，另一方面的问题是降低对节点故障的抵御能力，因为预留过多资源可能导致pod无法漂移到其他可用节点，进而导致无法启动。只有少部分服务适合用`Guaranteed`策略，其他大部分服务更适合`Burstable`策略，大致有如下几种划分思路：

   * 对重要的基础服务如注册中心、缓存服务等按`Guaranteed`策略来设置，这类服务需要保证稳定获得资源，并且资源需求上限不高。举例：

      ```yml
       resources:
         limits: { cpu: "1", memory: 2Gi }
         requests: { cpu: "1", memory: 2Gi }
     ```
> 由于cpu是可压缩资源不会像内存一样在不足时造成服务故障，所以还有折中的配置方式是仅配置内存上下限相等，而cpu存在上下限浮动。


   * 对应用服务采用`Burstable`策略，cpu可设置较大上下限差异比如0.5-2核，内存设置预留=上限1/2来设置比如2G-4G，这类服务资源需求波动大上限较高，还会运行多个副本作为负载，这样配置是更加符合资源共享高效利用的思路，同时也对资源有一定保障。举例：

     ```yml
       resources:
         limits: { cpu: "4", memory: 4Gi }
         requests: { cpu: "500m", memory: 2Gi }
     ```

   * 对于后台服务、管理服务等可以进一步减少预留如CPU0.1核和内存512M来减少资源预留的浪费，举例：
     ```yml
       resources:
         limits: { cpu: "1", memory: 2Gi }
         requests: { cpu: "100m", memory: 512Mi }
     ```
   > 后台服务也就是说平时访问少，与在线用户数相关性不大，通过观察空闲期服务资源占用可以得到后台服务应该设置的预留值

### 资源危机意识，保持一定的空闲资源避免满负荷
集群资源多时，必然是有多台主机多个节点，节点越多出现故障几率越大，即便有充足的资源也可能因为故障宕机导致实际环境变得不充足，为保障集群可用性需节点故障资源减少的情况。比如按16C+64G资源来估算资源的系统，实际所有pod资源预留值之和可控制为一半即8C+32G上下，避免资源临时不足产生的服务无法启动。



## 无感知地替换服务

> 主要思路：借助多副本、探针等策略，为快速迭代小步快跑创造环境，减少重启和更新带来的不可用。

使用容器云的优点之一是通过k8s提供的统一控制来管理大量服务器，简化大量服务的启停控制，极大降低管理成本。服务的启停控制方便，带来的是可以快速迭代更新，当服务重启更新时就需要减少对使用者的感知。

### 实例副本与调度策略

由于微服务系统同一个服务启动多个实例时可自动组成集群，在使用k8s时为服务设置2个副本或以上，就很容易的避免了单服务故障带来的不可用问题。

多副本的pod由kube-scheduler决定调度到哪个节点，kube-scheduler根据多种策略综合给节点打分而算出合适的节点，通常pod多个实例可以分散在不同的节点上，不过也有可能运行在相同的节点。对于可用性要求较高的情况，让pod多实例调度到不同节点更好，可以通过亲和与反亲和策略达到这个效果。

pod多副本部署在不同节点通过反亲和策略可以使用如下配置：

```yaml
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - nginx
            topologyKey: "kubernetes.io/hostname"
```

这也是k8s权威指南中的一个示例，不过由于`requiredDuringSchedulingIgnoredDuringExecution`具有强制性，对于pod副本数=节点数时不友好，比如pod有2个副本且集群有2个节点，重启时如果策略是" 先启动新Pod，再停止旧Pod "则新pod会一直处于等待状态` Scheduling`，且如果需要副本数>节点数更无法运行。

使用非强制性的策略`preferredDuringSchedulingIgnoredDuringExecution`，也可一定程度上实现分散效果。

```yaml
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - cnginx
                topologyKey: "kubernetes.io/hostname"
```



### 使用探针加强自动检测

默认情况下，pod启动后很快显示状态绿色，实际功能又不可用，需要等一段时间，健康状态指示失去应用的作用，这种情况就需要探针来解决。

探针作用就是对容器状态的探测，主要探针有：`livenessProbe`（存活探针）、`readinessProbe`（就绪探针）

* 存活探针用于判断容器是否正常存活，如果探测不通过会结束掉容器，通常容器重启策略会使其重启，举例zookeeper的存活探针，执行命令做检查：

  ```yaml
          livenessProbe:
            exec:
              command:
              - sh
              - -c
              - "zookeeper-ready 2181"
            initialDelaySeconds: 30
            timeoutSeconds: 5
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 5
  ```

  

* 就绪探针用于判断容器是否启动完毕，启动完毕的容器才会加入到SVC服务发现中，举例服务的就绪探针，检测TCP端口

  ```yaml
          readinessProbe:
            tcpSocket:
              port: 20880
            initialDelaySeconds: 10
            timeoutSeconds: 3
            periodSeconds: 5
            successThreshold: 1
            failureThreshold: 5
  ```

**通常每个容器都应配置就绪探针**，就绪探针对服务可用性帮助很大，且几乎不会引起负面效果，另一方面存活探针就要谨慎的配置，如果配置不当可能引起容器频繁的重启。配置就绪探针时最简单的可以使用TCP端口探测，如果有HTTP接口的可以使用HTTP探测，或使用执行命令探测。
> 就绪探针的`initialDelaySeconds`和`periodSeconds`可以短一些，更快的探测到服务是否就绪；存活探针的`initialDelaySeconds`和`periodSeconds`可以长一些，避免服务还没启动成功就被当做不健康而触发重启。

即便服务之间的发现与调用可能并不通过SVC，就绪探针对滚动更新也很有用：滚动更新时，当一个pod实例就绪后，才会开始下一个实例重启，也就是说同一时间只重启一个实例且等待启动完成能提供服务，更新期间一直有可用的服务，所以基本上非高峰期更新重启服务是可以做到无感知的。

## 灰度发布服务更新

> 主要思路：使用灰度服务环境检验更新，减少环境差异引发的意外，平滑升级。

即便在测试环境已经验证过的服务，在正式环境更新时也可能出现问题，两者的区别是正式环境实际使用情况很难被测试环境完全模拟，原因比如正式环境数据量大、访问量大、或可能存在特殊情况的数据，可能测试环境没问题而正式环境上线就有问题。

### 灰度服务与正式服务

灰度服务与正式服务的关系是：共用基础服务，服务访问隔离，提供不同入口或不同权重规则来分流。

在正式环境中加入一个独立的小环境，与正式环境共享基础服务与数据库，作为一个灰度服务环境，当需要做服务更新时，先更新灰度服务并进行验证，通过后再更新正式环境。更新灰度环境不影响正式环境，还可以较早做灰度更新，这样对于较大规模的系统的规避上线问题、顺利完成更新有很大帮助。

### 灰度服务的访问与更新

分离入口的灰度环境比较好理解，且控制简单。通过服务发现版本做隔离，服务基于Dubbo通信框架时默认支持了定义版本，定义正式服务版本`1.0.0`，灰度版本`1.9.9`，大小两套服务群即可互相隔离且共享基础服务。

![](https://bed.cdpt.pro/ibed/2021/12/16/DgeZa55Pc.png)

相同入口的灰度环境，通过权重分流，如果通过Nginx代理，则在`upstream`代理处配置权重分流；如果使用微服务网关，通常微服务体系可设置服务权重，如nacos可对服务实例设置其访问权重。一般的权重方式分流量有随机性，不能控制某些请求固定走灰度环境，更复杂的路由往往需要定义规则，且需要服务设计上的支持如区分header、cookie中的属性，复杂度较高。

![](https://bed.cdpt.pro/ibed/2021/12/16/DgeZa51Ps.png)

## 影响容器启动的一些因素

k8s创建pod与启动的整体流程环节很多，涉及很多组件协作，影响启动的因素就比较多。pod容器启动过程大致包括：

* 通过apiserver创建pod并将信息存储etcd
* 调度器scheduler监听到后为pod分配节点
* 节点上的kubelet通过控制循环管理pod生命周期，含创建、更新、删除等
* 当创建pod时，需先做准备工作包括为pod创建数据目录、挂载volume、拉取secrets、通过container runtime执行容器创建
* 创建容器包含sandbox容器、init容器、业务容器等，在容器启动时执行镜像拉取，并调用docker api启动

当容器启动后可以看到服务的启动日志，进而了解运行细节，而当容器未能成功启动时则不会有容器日志，此时就需要从pod流程上找问题因素，其中常见的影响启动的因素包括：

1. 没有可用节点，各节点都不满足运行pod条件，可能是资源不满足pod预留设置，节点有污点不可调度等。通常pod预留资源较多时更容易遇到此类情况，应格外注意。

2. 挂载卷失败，以网络存储方式实现的卷，容易因网络环境、权限、存储组件故障等导致挂载失败，以本地目录挂在的卷，受本地目录空间大小影响，通常主机不会预留特别多空间，数据卷挂载问题始终是一个不太稳定的因素。

3. 挂在密钥或配置映射失败，密钥secret和配置映射configmap是为容器注入配置信息的一种方式，如果对应内容丢失则引起挂载失败。

4. 拉取镜像失败，镜像损坏、丢失、仓库环境故障等会引起镜像拉取失败，有些云环境使用私有仓库，需要使用到`imagePullSecrets`拉取密钥。

5. init容器出错，pod使用了init容器时，如果其中执行失败则会导致pod无法启动

6. 容器状态不健康，通常是有探针检测而未通过，该项通常容器已启动并有日志输出，比如探针做端口检测而容器一直未能启动完成到监听端口（根据探测方式而定），或者存在探针配置错误的情况。

   